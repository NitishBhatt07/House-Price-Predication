{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c32761a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.pandas.set_option('Display.max_columns',None)\n",
    "pd.pandas.set_option('Display.max_rows',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f068bd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dfab69c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "(1459, 80)\n"
     ]
    }
   ],
   "source": [
    "train_Id = pd.DataFrame(train.Id)\n",
    "test_Id = pd.DataFrame(test.Id )\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21bf841",
   "metadata": {},
   "source": [
    "### All Numerical and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf1e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "numerical_features_train = [feature for feature in train.columns if train[feature].dtype != 'O']\n",
    "year_feature_train = [feature for feature in numerical_features_train if 'Yr' in feature or \"Year\" in feature]\n",
    "discrete_feature_train = [feature for feature in numerical_features_train if len(train[feature].unique()) <=25 \n",
    "                    and feature not in year_feature_train]\n",
    "continuous_feature_train = [feature for feature in numerical_features_train \n",
    "                      if feature not in discrete_feature_train and feature not in year_feature_train] \n",
    "categorical_feature_train = [feature for feature in train.columns if train[feature].dtype == 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3761de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "numerical_features_test = [feature for feature in test.columns if test[feature].dtype != 'O']\n",
    "year_feature_test = [feature for feature in numerical_features_test if 'Yr' in feature or \"Year\" in feature]\n",
    "discrete_feature_test = [feature for feature in numerical_features_test if len(test[feature].unique()) <=25 \n",
    "                    and feature not in year_feature_test]\n",
    "continuous_feature_test = [feature for feature in numerical_features_test \n",
    "                      if feature not in discrete_feature_test and feature not in year_feature_test] \n",
    "categorical_feature_test = [feature for feature in test.columns if test[feature].dtype == 'O']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4450015",
   "metadata": {},
   "source": [
    "### Missing Values in Year Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4a0f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the year to ages\n",
    "for feature in year_feature_train:\n",
    "    if feature != 'YrSold':\n",
    "        train[feature] = train['YrSold'] - train[feature]\n",
    "\n",
    "# fillng GarageYrBlt value with median\n",
    "train['GarageYrBlt'] = train['GarageYrBlt'].fillna(train.GarageYrBlt.median())\n",
    "\n",
    "# droping the YrSold feature\n",
    "train = train.drop('YrSold',axis=1)\n",
    "\n",
    "# new list after removing YrSold\n",
    "year_feature_train_new = year_feature_train[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49355ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in year_feature_test:\n",
    "    if feature != 'YrSold':\n",
    "        test[feature] = test['YrSold'] - test[feature]\n",
    "        \n",
    "# fillng GarageYrBlt value with median\n",
    "test['GarageYrBlt'] = test['GarageYrBlt'].fillna(test.GarageYrBlt.median())\n",
    "\n",
    "# droping the YrSold feature\n",
    "test = test.drop('YrSold',axis=1)\n",
    "\n",
    "# new list after removing YrSold\n",
    "year_feature_test_new = year_feature_test[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15914dc",
   "metadata": {},
   "source": [
    "### Missing Value in Discrete Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4068629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are no missing value in Discrete Feature of train dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfff7bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test discrete feature nan\n",
    "discrete_feature_test_nan = [feature for feature in discrete_feature_test if test[feature].isnull().sum() >=1 ]\n",
    "\n",
    "# filling nan with median\n",
    "for feature in discrete_feature_test_nan:\n",
    "    test[feature] = test[feature].fillna(test[feature].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec1dcbe",
   "metadata": {},
   "source": [
    "### Missing Value in Continuous Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "690400f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "# only missing value in one feature LotFrontage\n",
    "train['LotFrontage_Nan'] = np.where(train['LotFrontage'].isnull(),1,0)\n",
    "train['LotFrontage'] = train['LotFrontage'].fillna(train.LotFrontage.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a76e9282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "continuous_feature_test_nan = [feature for feature in continuous_feature_test if test[feature].isnull().sum() >=1 ]\n",
    "\n",
    "for feature in continuous_feature_test_nan:\n",
    "    # capturing the importance of Nan value\n",
    "    # creating the new feature which contain the Nan value\n",
    "    test[feature+'_Nan'] = np.where(test[feature].isnull(),1,0)\n",
    "    \n",
    "    # replacing with median\n",
    "    test[feature] = test[feature].fillna(test[feature].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e5f99a",
   "metadata": {},
   "source": [
    "### Missing value in Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebe68d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "categorical_feature_train_nan = [feature for feature in categorical_feature_train if train[feature].isnull().sum() >=1 ]\n",
    "\n",
    "for feature in categorical_feature_train_nan:\n",
    "    # replacing value with new label\n",
    "    train[feature] = train[feature].fillna('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27f128e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "categorical_feature_test_nan = [feature for feature in categorical_feature_test if test[feature].isnull().sum() >=1 ]\n",
    "\n",
    "for feature in categorical_feature_test_nan:\n",
    "    # replacing value with new label\n",
    "    test[feature] = test[feature].fillna('Missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e30651",
   "metadata": {},
   "source": [
    "## Continuous Features Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a98430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "for feature in continuous_feature_train:\n",
    "    train[feature] = np.log1p(train[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "674ebe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "for feature in continuous_feature_test:\n",
    "    test[feature] = np.log1p(test[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54f78bd",
   "metadata": {},
   "source": [
    "## Handling Rare Categorical Feature\n",
    "We will remove categorical variables that are present less than 1% of the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f87233ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "for feature in categorical_feature_train:\n",
    "    temp = train[feature].value_counts()/len(train)\n",
    "    temp_df = temp[temp > 0.01].index\n",
    "    train[feature] = np.where(train[feature].isin(temp_df),train[feature],'Rare_var')\n",
    "    \n",
    "# test\n",
    "for feature in categorical_feature_test:\n",
    "    temp = test[feature].value_counts()/len(test)\n",
    "    temp_df = temp[temp > 0.01].index\n",
    "    test[feature] = np.where(test[feature].isin(temp_df),test[feature],'Rare_var')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fdf87c",
   "metadata": {},
   "source": [
    "## Conerting Categorical to Numerical Variable\n",
    "1. One Hot Encoding for which have less then 6 categories  (but not used)\n",
    "2. Frequency Label Encoding for which has More then 6 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0949ff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "# label encoding for other features based on frequentness\n",
    "for feature in categorical_feature_train:\n",
    "    label_ordered = train[feature].value_counts().index\n",
    "    label_ordered = {k:i for i,k in enumerate(label_ordered,0)}\n",
    "    train[feature] = train[feature].map(label_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb38ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "# label encoding for other features based on frequentness\n",
    "for feature in categorical_feature_test:\n",
    "    label_ordered = test[feature].value_counts().index\n",
    "    label_ordered = {k:i for i,k in enumerate(label_ordered,0)}\n",
    "    test[feature] = test[feature].map(label_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ff706be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ac54642",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 86)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f43225",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "1. Standardization(StandardScaler) : follows Standard Normal Distribution where mean = 0 and std = 1\n",
    "2. Normalization(MinMAxScaler) : convert values in range 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c766c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "scaled_feature = [feature for feature in train.columns if feature not in ['SalePrice']] \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train[scaled_feature])\n",
    "\n",
    "# transform the train and test set, and add on the Id and SalePrice variables\n",
    "train = pd.concat([train[['SalePrice']].reset_index(drop=True),\n",
    "                    pd.DataFrame(scaler.transform(train[scaled_feature]), columns=scaled_feature)],\n",
    "                    axis=1)\n",
    "\n",
    "## got some missing value here\n",
    "train['MasVnrArea'] = train['MasVnrArea'].fillna(train.MasVnrArea.median())\n",
    "train.to_csv('processed_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9ec71cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(test)\n",
    "\n",
    "# transform the train and test set, and add on the Id and SalePrice variables\n",
    "test = pd.DataFrame(scaler.transform(test), columns=test.columns)\n",
    "\n",
    "test.to_csv('processed_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fa4d0a",
   "metadata": {},
   "source": [
    "## Apply Feature Selection\n",
    "1. first, I specify the Lasso Regression model, and I\n",
    "2. select a suitable alpha (equivalent of penalty).\n",
    "3. The bigger the alpha the less features that will be selected. 4 Then I use the selectFromModel object from sklearn, which will select the features which coefficients are non-zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad9703bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d442116",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_main = train.drop(['SalePrice'],axis=1)\n",
    "X_test_main = test\n",
    "y_train_main = train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70205bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12.247699\n",
       "1    12.109016\n",
       "2    12.317171\n",
       "3    11.849405\n",
       "4    12.429220\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54ae9210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=Lasso(alpha=0.005, random_state=0))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_Sel_model = SelectFromModel(Lasso(alpha=0.005, random_state=0))\n",
    "feature_Sel_model.fit(X_train_main,y_train_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec6a1a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False,  True,  True, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False,  True,  True, False,  True, False,\n",
       "       False,  True, False, False,  True, False, False, False,  True,\n",
       "       False, False,  True, False, False, False, False,  True, False,\n",
       "       False, False, False,  True,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_Sel_model.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0eb9cb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 80\n",
      "selected features: 18\n",
      "features with coefficients shrank to zero: 62\n"
     ]
    }
   ],
   "source": [
    "# this is how we can make a list of the selected features\n",
    "selected_features = X_train_main.columns[(feature_Sel_model.get_support())]\n",
    "\n",
    "print('total features: {}'.format((X_train_main.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_features)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "    np.sum(feature_Sel_model.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be7ad44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_main = X_train_main[selected_features]\n",
    "X_test_main = X_test_main[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e2b219",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "1. Linear Regression\n",
    "2. Ridge Regression \n",
    "3. Lasso Regression \n",
    "4. Decision Tree Regression \n",
    "5. Random Forest\n",
    "6. KNN Model \n",
    "7. Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d986f",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4119e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_train_main,y_train_main,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9e81967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "171cc293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score :0.9307244153719043\n",
      "R2 score : 0.8514957449600788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr = SVR(kernel='rbf')\n",
    "svr.fit(X_train,y_train)\n",
    "print(f\"Train Score :{svr.score(X_train,y_train)}\")\n",
    "y_pred = svr.predict(X_test)\n",
    "print(f\"R2 score : {r2_score(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "725516c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score :0.8775523377429749\n",
      "R2 score : 0.8564952903702293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train,y_train)\n",
    "print(f\"Train Score :{ridge.score(X_train,y_train)}\")\n",
    "y_pred = ridge.predict(X_test)\n",
    "print(f\"R2 score : {r2_score(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "baa8ae8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score :0.9810434746974479\n",
      "R2 score : 0.8521392457333195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train,y_train)\n",
    "print(f\"Train Score :{rfr.score(X_train,y_train)}\")\n",
    "y_pred = rfr.predict(X_test)\n",
    "print(f\"R2 score : {r2_score(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ce936bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score :0.9986238592708129\n",
      "R2 score : 0.840065896141658\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgbr = XGBRegressor()\n",
    "xgbr.fit(X_train,y_train)\n",
    "print(f\"Train Score :{xgbr.score(X_train,y_train)}\")\n",
    "y_pred = xgbr.predict(X_test)\n",
    "print(f\"R2 score : {r2_score(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43ee3815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score :0.9999764189533585\n",
      "R2 score : 0.7143816151116931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train,y_train)\n",
    "print(f\"Train Score :{dt.score(X_train,y_train)}\")\n",
    "y_pred = dt.predict(X_test)\n",
    "print(f\"R2 score : {r2_score(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105a322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b33114f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c551aaa9",
   "metadata": {},
   "source": [
    "### selected model Xgboost and RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0390892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train_main,y_train_main)\n",
    "y_predicted = rfr.predict(X_test_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "789c6fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(y_predicted)\n",
    "sub_df = pd.read_csv('sample_submission.csv')\n",
    "datasets = pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('house3_submission_RFR.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52bbfbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgbr = XGBRegressor()\n",
    "xgbr.fit(X_train_main,y_train_main)\n",
    "y_predicted = xgbr.predict(X_test_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5a8404ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(y_predicted)\n",
    "sub_df = pd.read_csv('sample_submission.csv')\n",
    "datasets = pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('house3_submission_XGBR.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b8317e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5e42bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
